import torch.nn as nn
import torch
import torch.optim as optim
import torch.nn.functional as F
import random
from tqdm import tqdm

from making_dict import tensorsFromPair, tensorFromSentence

teacher_force_ratio = 0.5
MAX_LENGTH = 20
EOS_token = 1


def Model(
    model, input_tensor, target_tensor, model_optimizer, criterion
):  # ëª¨ë¸ì˜ loss ê³„ì‚°í•˜ëŠ” ë¶€ë¶„ ì •ì˜
    model_optimizer.zero_grad()
    input_lengt = input_tensor.size()

    loss = 0
    epoch_loss = 0
    output = model(input_tensor, target_tensor)
    num_iter = output.size(0)

    for ot in range(num_iter):
        loss += criterion(output[ot], target_tensor[ot])  # indexë¡œ ê³„ì‚°..!

    loss.backward()
    model_optimizer.step()
    epoch_loss = loss.item() / num_iter

    return epoch_loss


def trainModel(model, input_lang, output_lang, pairs, num_iteration=20000):
    print("ğŸš€Start TrainingğŸš€")
    model.train()
    optimizer = optim.Adam(model.parameters(), lr=0.01)
    criterion = nn.NLLLoss()  # CEì™€ ë˜‘ê°™ì€ë°, ì´ê±´ ë§ˆì§€ë§‰ì— softmaxê°€ ì—†ìŒ! ë”°ë¡œ ëª…ì‹œí•´ì¤˜ì•¼ë¨
    total_loss_iterations = 0

    training_pairs = [
        tensorsFromPair(input_lang, output_lang, random.choice(pairs))
        for i in range(num_iteration)
    ]  # ë°˜ë³µí•˜ ã„¹ëŒ€ë§ˆë‹¤ pairì˜ tensor list ë°˜í™˜ (data, target)

    for iter in tqdm(range(1, num_iteration + 1)):
        training_pair = training_pairs[iter - 1]
        input_tensor = training_pair[0]
        target_tensor = training_pair[1]

        loss = Model(model, input_tensor, target_tensor, optimizer, criterion)
        total_loss_iterations += loss

        if iter % 5000 == 0:
            avg_loss = total_loss_iterations / 5000
            total_loss_iterations = 0
            print(f"EPOCH : {iter}\t LOSS : {avg_loss:3f}")

    torch.save(model.state_dict(), "./training.pt")

    return model


def evalueate(model, input_lang, output_lang, sentences, max_length=MAX_LENGTH):
    print("âœ¨Start Evaluationâœ¨")
    with torch.no_grad():
        input_tensor = tensorFromSentence(input_lang, sentences[0])
        output_tensor = tensorFromSentence(output_lang, sentences[1])

        decoded_words = []
        output = model(input_tensor, output_tensor)

        for ot in range(output.size(0)):
            topv, topi = output[ot].topk(1)  # ê° ì¶œë ¥ì—ì„œ ê°€ì¥ ë†’ì€ ê°’ê³¼ ì¸ë±ìŠ¤ ë°˜í™˜

            if topi[0].item() == EOS_token:  # ëë‚¬ë‹¤ê³  íŒë‹¨í•˜ë©´...
                decoded_words.append("<EOS>")
                break
            else:  # ê³„ì† ë°˜ë³µ
                decoded_words.append(
                    output_lang.index2word[topi[0].item()]
                )  # ê°€ì¥ í™•ë¥ ì´ ë†’ì€ ë‹¨ì–´ì˜ indexë¡œ wordë¥¼ ì°¾ì•„ì„œ append í•¨

    return decoded_words


def evaluateRandomly(model, input_lang, output_lang, pairs, n=10):
    for i in range(n):
        pair = random.choice(pairs)  # ëœë¤í•œ ë¬¸ì¥ì„ ê°€ì ¸ì˜´
        print(f"Input : {pair[0]}")
        print(f"Output : {pair[1]}")
        output_words = evalueate(model, input_lang, output_lang, pair)
        output_sentence = " ".join(output_words)
        print(f"Predicted : {output_sentence}")
